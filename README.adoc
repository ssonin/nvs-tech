= NVS Tech Search API
:toc:
:toc-placement!:

image:https://img.shields.io/badge/vert.x-5.0.6-purple.svg[link="https://vertx.io"]
image:https://img.shields.io/badge/java-21-blue.svg[link="https://openjdk.org/"]
image:https://img.shields.io/badge/python-3.11-blue.svg[link="https://www.python.org/"]
image:https://img.shields.io/badge/postgresql-16-blue.svg[link="https://www.postgresql.org/"]

A REST API for managing clients and documents with advanced hybrid search capabilities powered by PostgreSQL full-text search and vector similarity.

toc::[]

== Overview

This application provides a searchable repository of clients and their associated documents. The search functionality combines PostgreSQL's full-text search with semantic vector search using pgvector, enabling both keyword matching and conceptual similarity searches.

=== Key Features

* *Client Management*: Create and retrieve client records with contact information
* *Document Management*: Attach documents to clients with searchable content
* *Hybrid Search*:
** Full-text search for direct keyword matches with relevance ranking
** Semantic vector search for conceptually similar content
** Reciprocal Rank Fusion (RRF) to combine and rank results from both approaches
** Unified search across both clients and documents

=== Technology Stack

* *Runtime*: Java 21
* *Framework*: Vert.x 5.0.6 (Web, Native PostgreSQL Client)
* *Database*: PostgreSQL 16 with full-text search and pgvector extension
* *Embeddings*: Python 3.11 microservice with sentence-transformers (all-MiniLM-L6-v2)
* *Migrations*: Flyway 11.7.2
* *Build*: Gradle 8.11 with Shadow plugin
* *Containerisation*: Docker with multi-stage builds
* *Testing*: JUnit 5 with Testcontainers and WireMock

==== Why Vert.x + PostgreSQL?

This stack is chosen for its exceptional performance and efficiency:

* *Performance*: Vert.x with PostgreSQL consistently ranks among the fastest Java frameworks in link:https://www.techempower.com/benchmarks/#section=data-r23&test=fortune[TechEmpower benchmarks]
* *Native PostgreSQL Driver*: Vert.x uses a reactive, non-blocking PostgreSQL client (not JDBC)
* *SQL Pipelining*: Batch multiple queries efficiently without round-trip overhead
* *Asynchronous Core*: Event-loop based architecture provides better scalability than traditional blocking I/O
* *Resource Efficiency*: Handles thousands of concurrent connections with minimal threads

This makes it ideal for I/O-intensive applications like search APIs where database interaction is the primary bottleneck.

== Getting Started

=== Prerequisites

* Docker and Docker Compose
* (Optional) Java 21 and Gradle 8+ for local development

=== Quick Start

1. Clone the repository:
+
[source,bash]
----
git clone <repository-url>
cd nvs-tech
----

2. Start the application:
+
[source,bash]
----
docker compose up --build
----
+
This will:

* Build and start PostgreSQL 16 with pgvector extension
* Build and start the embedding service (downloads the ML model on first run)
* Apply database migrations automatically via Flyway
* Build and start the application on port 8888

3. Verify the application is running:
+
[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=test"
----
This will return `200 OK` with an empty array `[]` if no data exists, which confirms the app is running.

4. Stop the application:
+
[source,bash]
----
docker compose down
----
+
To remove volumes as well:
+
[source,bash]
----
docker compose down -v
----

5. Clean rebuild and restart (stops containers, removes volumes/data, rebuilds images, and starts fresh):
+
[source,bash]
----
docker compose down -v && docker compose up --build
----

=== Configuration

Environment variables (with defaults):

[cols="1,1,3"]
|===
|Variable |Default |Description

|`PGHOST`
|`postgres`
|PostgreSQL host

|`PGPORT`
|`5432`
|PostgreSQL port

|`PGDATABASE`
|`nvs_tech`
|Database name

|`PGUSER`
|`nvs_tech`
|Database user

|`PGPASSWORD`
|`nvs_tech`
|Database password

|`HTTP_PORT`
|`8888`
|HTTP server port

|`EMBEDDING_SERVICE_HOST`
|`embedding`
|Embedding service host

|`EMBEDDING_SERVICE_PORT`
|`8000`
|Embedding service port
|===

Override in `docker-compose.yml` or create a `.env` file.

== API Documentation

Full OpenAPI 3.1 specification available in link:src/main/resources/openapi.yml[openapi.yml].

=== Endpoints

==== Create Client

[source,bash]
----
POST /api/v1/clients
Content-Type: application/json

{
  "first_name": "Chandler",
  "last_name": "Bing",
  "email": "chandler.bing@neviswealth.com",
  "description": "Sarcastic, self-deprecating office worker with a sharp sense of humor, known for cracking jokes to deflect awkward situations."
}
----

*Response*: `201 Created`
[source,json]
----
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "created_at": "2024-12-22T10:30:00Z",
  "first_name": "Chandler",
  "last_name": "Bing",
  "email": "chandler.bing@neviswealth.com",
  "description": "Sarcastic, self-deprecating office worker with a sharp sense of humor, known for cracking jokes to deflect awkward situations."
}
----

==== Get Client

[source,bash]
----
GET /api/v1/clients/{id}
----

*Response*: `200 OK` (same schema as create response)

==== Create Document

[source,bash]
----
POST /api/v1/clients/{client_id}/documents
Content-Type: application/json

{
  "title": "Chandler Bing's Utility Bill of Awkwardness",
  "content": "This official-looking utility bill details the excessive energy I've wasted trying to explain my job to my parents and the high emotional charges from every failed relationship since Janice. It also includes a surprise late fee for that one time I accidentally proposed, because apparently sarcasm doesn't show up on the meter. Could this BE any more expensive?"
}
----

*Response*: `201 Created`
[source,json]
----
{
  "id": "660e8400-e29b-41d4-a716-446655440001",
  "created_at": "2024-12-22T10:35:00Z",
  "client_id": "550e8400-e29b-41d4-a716-446655440000",
  "title": "Chandler Bing's Utility Bill of Awkwardness",
  "content": "This official-looking utility bill details the excessive energy I've wasted trying to explain my job to my parents and the high emotional charges from every failed relationship since Janice. It also includes a surprise late fee for that one time I accidentally proposed, because apparently sarcasm doesn't show up on the meter. Could this BE any more expensive?"
}
----

==== Search

[source,bash]
----
GET /api/v1/search?q={query}
----

*Response*: `200 OK`
[source,json]
----
[
  {
    "type": "client",
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "created_at": "2024-12-22T10:30:00Z",
    "first_name": "Chandler",
    "last_name": "Bing",
    "email": "chandler.bing@neviswealth.com",
    "description": "Sarcastic, self-deprecating office worker...",
    "rank": 0.607927
  },
  {
    "type": "document",
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "created_at": "2024-12-22T10:35:00Z",
    "client_id": "550e8400-e29b-41d4-a716-446655440000",
    "title": "Chandler Bing's Utility Bill of Awkwardness",
    "content": "This official-looking utility bill details...",
    "rank": 0.456234
  }
]
----

Results are sorted by relevance (rank) in descending order.

== Example Usage

Using the example client and document from the API documentation above, here are various search scenarios demonstrating the capabilities:

=== Direct Term Match (Full-Text Search)

Search for documents containing "utility bill":

[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=utility+bill"
----

Returns Chandler's document as a direct match on "utility bill" in the content via full-text search.

=== Semantic Search (Vector Similarity)

Search for "energy costs" or "monthly expenses":

[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=address+proof"
----

Returns Chandler's utility bill document even though it doesn't contain "address proof" - the vector search finds it based on semantic similarity to the document's content.

=== Name-Based Search

Search across both resources by name:

[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=chandler"
----

Returns:

* *Client*: Matches by first name
* *Document*: Matches by title ("Chandler Bing's Utility Bill...")

=== Content and Description Search

Search for "awkward":

[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=awkward"
----

Returns:

* *Client*: Matches by description ("...deflect awkward situations")
* *Document*: Matches by content ("...Utility Bill of Awkwardness")

=== Email Domain Search

Search for clients by company:

[source,bash]
----
curl "http://localhost:8888/api/v1/search?q=NevisWealth"
----

Returns Chandler's client record by matching the email domain (`chandler.bing@neviswealth.com`). The email field is tokenised by splitting on special characters (`@`, `.`, `_`, `+`, `-`).

=== Complete Workflow Example

[source,bash]
----
# 1. Create a client
CLIENT_ID=$(curl -s -X POST http://localhost:8888/api/v1/clients \
  -H "Content-Type: application/json" \
  -d '{
    "first_name": "Chandler",
    "last_name": "Bing",
    "email": "chandler.bing@neviswealth.com",
    "description": "Sarcastic, self-deprecating office worker with a sharp sense of humor, known for cracking jokes to deflect awkward situations."
  }' | jq -r '.id')

# 2. Add a document
curl -X POST "http://localhost:8888/api/v1/clients/${CLIENT_ID}/documents" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Chandler Bing'\''s Utility Bill of Awkwardness",
    "content": "This official-looking utility bill details the excessive energy I'\''ve wasted trying to explain my job to my parents and the high emotional charges from every failed relationship since Janice. It also includes a surprise late fee for that one time I accidentally proposed, because apparently sarcasm doesn'\''t show up on the meter. Could this BE any more expensive?"
  }'

# 3. Search by direct term (full-text search)
curl "http://localhost:8888/api/v1/search?q=utility+bill"

# 4. Search by semantic similarity (vector search)
curl "http://localhost:8888/api/v1/search?q=address+proof"

# 5. Search by name
curl "http://localhost:8888/api/v1/search?q=chandler"

# 6. Retrieve client details
curl "http://localhost:8888/api/v1/clients/${CLIENT_ID}"
----

== Testing with Postman

A Postman collection with example requests is available at link:src/test/resources/postman/nvs-tech.postman_collection.json[nvs-tech.postman_collection.json].

To use:

1. Import the collection into Postman
2. Ensure the application is running (`docker compose up --build`)
3. Run requests or the entire collection

The collection includes:

* Create and retrieve operations for clients
* Create operation for documents
* Various search scenarios

== Architecture & Design Decisions

=== Hybrid Search Implementation

The application combines two complementary search approaches to provide comprehensive search capabilities:

==== Full-Text Search (FTS)

PostgreSQL's native full-text search handles keyword-based queries with:

* *Stemming*: Matches word variations (e.g., "running" matches "run")
* *Stop word removal*: Ignores common words like "the", "a", "is"
* *Relevance ranking*: Uses `ts_rank` to score matches by importance

==== Vector Search (Semantic Similarity)

pgvector extension enables semantic search using embeddings:

* *Model*: all-MiniLM-L6-v2 (384-dimensional embeddings)
* *Similarity metric*: Cosine similarity via `++<=>++` operator
* *Indexing*: HNSW (Hierarchical Navigable Small World) for fast approximate nearest-neighbor search

==== Reciprocal Rank Fusion (RRF)

Results from both search methods are combined using RRF, which:

* Merges ranked lists without requiring score normalisation
* Balances contributions from both FTS and vector search
* Uses the formula: `1 / (k + rank_position)` where k=60 is a smoothing constant

[source,sql]
----
WITH fts_results AS (
  SELECT id, ROW_NUMBER() OVER (ORDER BY ts_rank(...) DESC) AS rank_pos
  FROM documents WHERE search @@ plainto_tsquery('english', $1)
  LIMIT 20
),
vector_results AS (
  SELECT id, ROW_NUMBER() OVER (ORDER BY embedding <=> $2::vector) AS rank_pos
  FROM documents WHERE embedding IS NOT NULL
  ORDER BY embedding <=> $2::vector
  LIMIT 20
),
combined AS (
  SELECT id,
    COALESCE(1.0 / (60 + fts.rank_pos), 0) +
    COALESCE(1.0 / (60 + vec.rank_pos), 0) AS rrf_score
  FROM fts_results fts
  FULL OUTER JOIN vector_results vec USING (id)
)
SELECT ... FROM combined ORDER BY rrf_score DESC;
----

=== Vector Search & Embeddings

==== Embedding Service

A lightweight Python microservice generates embeddings:

* *Framework*: FastAPI with uvicorn
* *Model*: sentence-transformers/all-MiniLM-L6-v2
* *Output*: 384-dimensional float vectors
* *Endpoint*: `POST /embeddings` accepts batch text input

[source,python]
----
model = SentenceTransformer("all-MiniLM-L6-v2")

@app.post("/embeddings")
def get_embeddings(request: EmbeddingRequest):
    embeddings = model.encode(request.texts)
    return EmbeddingResponse(embeddings=embeddings.tolist())
----

==== Embedding Storage

Document embeddings are stored in PostgreSQL using pgvector:

[source,sql]
----
embedding vector(384)
----

Embeddings are generated when documents are created and stored alongside the document content.

==== HNSW Index

For efficient similarity search, an HNSW index is created on the embedding column:

[source,sql]
----
CREATE INDEX documents_embedding_idx
  ON documents USING hnsw (embedding vector_cosine_ops);
----

HNSW provides:

* *Fast queries*: Logarithmic time complexity for nearest-neighbor search
* *High recall*: Typically >95% accuracy compared to exact search
* *Memory efficiency*: Graph-based structure with tuneable parameters

=== Full-Text Search Configuration

==== Text Search Vectors

Pre-computed `tsvector` columns are generated automatically using PostgreSQL's `GENERATED ALWAYS AS` syntax:

[source,sql]
----
search tsvector GENERATED ALWAYS AS (
  setweight(to_tsvector('english', coalesce(first_name, '')), 'A') ||
  setweight(to_tsvector('english', coalesce(last_name, '')), 'A') ||
  setweight(to_tsvector('english', regexp_replace(coalesce(email, ''), '[@._+\-]+', ' ', 'g')), 'B') ||
  setweight(to_tsvector('english', coalesce(description, '')), 'C')
) STORED
----

Weight priorities: `A` (name) > `B` (email) > `C` (description)

==== Email Tokenisation

Email addresses are tokenised by replacing special characters with spaces:

[source,sql]
----
regexp_replace(email, '[@._+\-]+', ' ', 'g')
----

This allows searching by domain (e.g., "NevisWealth") or username components.

==== GIN Indexes

Generalised Inverted Indexes provide fast full-text lookups:

[source,sql]
----
CREATE INDEX clients_search_idx ON clients USING GIN (search);
CREATE INDEX documents_search_idx ON documents USING GIN (search);
----

=== Query Strategy

The search endpoint executes a hybrid search strategy:

1. *Generate query embedding*: The search query is sent to the embedding service
2. *Parallel execution*: FTS and vector searches run concurrently
3. *Client search*: Full-text search only (clients don't have embeddings)
4. *Document search*: Hybrid search with RRF ranking
5. *Merge results*: Combine client and document results, sorted by rank

[source,java]
----
final Comparator<JsonObject> byRank = comparingDouble(it -> it.getDouble("rank"));
fetchEmbeddings(query)
  .compose(embeddings -> Future.all(
    searchClients(query),
    searchDocuments(query, embeddings)))
  .map(composite -> {
    final JsonArray clients = composite.resultAt(0);
    final JsonArray documents = composite.resultAt(1);
    return Stream.concat(clients.stream(), documents.stream())
      .map(it -> (JsonObject) it)
      .sorted(byRank.reversed())
      .toList();
  });
----

=== Why Hybrid Search with PostgreSQL?

For this use case, combining FTS and vector search in PostgreSQL provides:

* *Best of both worlds*: Exact keyword matching plus semantic understanding
* *Excellent performance*: Sub-millisecond queries with proper indexing
* *Built-in relevance ranking*: `ts_rank` for FTS, cosine similarity for vectors
* *No additional infrastructure*: pgvector eliminates the need for a separate vector database
* *ACID guarantees*: Data consistency with transactional updates
* *Simpler deployment*: Single database container vs. multi-component stack
* *Lower operational overhead*: Fewer moving parts to monitor and maintain

Trade-offs:

* Not suitable for very large datasets (>10M documents with embeddings)
* Less sophisticated than dedicated vector databases for pure semantic search
* Embedding service adds a microservice dependency
* Limited real-time update capabilities compared to specialised solutions

For a focused demo project with moderate data volumes, PostgreSQL with pgvector provides the best balance of features, performance, and simplicity.

=== Vert.x Architecture

The application follows Vert.x best practices with a verticle-based architecture:

==== Verticles

* *App*: Main verticle that orchestrates startup, runs Flyway migrations, and deploys other verticles
* *ApiVerticle*: HTTP layer handling routing, request/response formatting, and error handling
* *RepositoryVerticle*: Data access layer managing PostgreSQL interactions
* *EmbeddingVerticle*: Communicates with the embedding service via HTTP

==== Event Bus Communication

Verticles communicate via Vert.x's distributed event bus:

[source,java]
----
vertx.eventBus()
  .<JsonObject>request("clients.create", payload)
  .onSuccess(reply -> ...)
  .onFailure(ctx::fail);

vertx.eventBus()
  .<JsonArray>request("embeddings.get", message)
  .map(Message::body);
----

Benefits:

* *Decoupling*: API, repository, and embedding layers are independent
* *Testability*: Easy to mock event bus for unit tests
* *Scalability*: Event bus supports clustering (though not needed here)

==== Reactive PostgreSQL Client

Uses Vert.x's native reactive PostgreSQL client:

[source,java]
----
pool.withConnection(conn ->
  conn.preparedQuery(insertClient())
    .execute(values)
    .map(rows -> clientFromRow(rows.iterator().next()))
)
----

Advantages over JDBC:

* *Non-blocking I/O*: Doesn't tie up threads waiting for database responses
* *Connection pooling*: Built-in reactive pool management
* *Prepared statements*: Native protocol-level preparation
* *Pipeline support*: Batch multiple commands in a single network round-trip

=== Database Schema

The schema uses several PostgreSQL features:

* *Generated columns*: Automatic tsvector maintenance for full-text search
* *Vector columns*: 384-dimensional embeddings stored via pgvector
* *HNSW index*: Fast approximate nearest-neighbor search on embeddings
* *GIN indexes*: Efficient full-text search lookups
* *Partial unique indexes*: `UNIQUE (lower(email)) WHERE state = 'ACTIVE'`
* *Soft deletes*: `state` column enables logical deletion (prepared for future use)
* *Timestamps*: Automatic `created_at` and `updated_at` tracking

See migrations in link:src/main/resources/db/migration/[src/main/resources/db/migration/]:

* link:src/main/resources/db/migration/V001__create_clients_table.sql[V001]: Clients table with search vectors
* link:src/main/resources/db/migration/V002__create_documents_table.sql[V002]: Documents table with search vectors, embeddings, and HNSW index

== Development

=== Local Development

1. Start PostgreSQL and the embedding service:
+
[source,bash]
----
docker compose up --build postgres embedding
----

2. Package the application:
+
[source,bash]
----
./gradlew clean assemble
----

3. Run the application:
+
[source,bash]
----
./gradlew clean run
----

=== Running Tests

[source,bash]
----
./gradlew clean test
----

Integration tests use Testcontainers to spin up a PostgreSQL instance automatically and WireMock to mock the embedding service, ensuring tests run against realistic infrastructure without external dependencies.

=== Building Fat JAR

[source,bash]
----
./gradlew clean shadowJar
----

The fat JAR will be available at `build/libs/nvs-tech-1.0.0-SNAPSHOT-fat.jar`.

== Known Limitations & Future Enhancements

=== Current Limitations

* *No document content summarisation*: The optional feature has not been implemented
* *Limited error messages*: Error responses are basic and could be more descriptive
* *No pagination*: Search results return all matches (acceptable for small datasets)
* *No authentication*: Endpoints are publicly accessible
* *Case-insensitive search only*: PostgreSQL text search normalises all input
* *Client search is FTS-only*: Clients don't have embeddings for semantic search

=== Potential Enhancements

* *Document Summarisation*: LLM-based content summarisation using Claude API
* *Client Embeddings*: Add vector search for clients based on description
* *Advanced Ranking*: Custom boost factors, phrase matching, proximity scoring
* *Result Highlighting*: Return matched snippets with search terms highlighted
* *Faceted Search*: Filter by client, date range, document type
* *Pagination*: Limit and offset parameters for large result sets
* *Fuzzy Matching*: Typo tolerance using trigram similarity
* *Audit Trail*: Track document changes and access patterns
* *Rate Limiting*: Protect against abuse
* *Authentication & Authorisation*: JWT-based API security
* *Embedding Model Upgrade*: Larger models for improved semantic understanding

== Troubleshooting

=== Application won't start

Check logs:
[source,bash]
----
docker compose logs app
----

Ensure PostgreSQL is healthy:
[source,bash]
----
docker compose ps postgres
----

Ensure embedding service is healthy:
[source,bash]
----
docker compose ps embedding
curl http://localhost:8000/health
----

=== Search returns no results

Verify data exists:
[source,bash]
----
docker exec -it nvs-tech-postgres psql -U nvs_tech -d nvs_tech -c "SELECT COUNT(*) FROM clients;"
docker exec -it nvs-tech-postgres psql -U nvs_tech -d nvs_tech -c "SELECT COUNT(*) FROM documents;"
----

Check search vector generation:
[source,bash]
----
docker exec -it nvs-tech-postgres psql -U nvs_tech -d nvs_tech -c "SELECT id, search FROM clients LIMIT 1;"
----

Verify embeddings are stored:
[source,bash]
----
docker exec -it nvs-tech-postgres psql -U nvs_tech -d nvs_tech -c "SELECT id, embedding IS NOT NULL as has_embedding FROM documents LIMIT 5;"
----

=== Embedding service issues

Check embedding service logs:
[source,bash]
----
docker compose logs embedding
----

Test embedding generation directly:
[source,bash]
----
curl -X POST http://localhost:8000/embeddings \
  -H "Content-Type: application/json" \
  -d '{"texts": ["test query"]}'
----

The response should contain a 384-dimensional embedding array.

=== Database migration issues

Reset the database:
[source,bash]
----
docker compose down -v
docker compose up --build
----

== References

* link:https://vertx.io/docs/[Vert.x Documentation]
* link:https://www.techempower.com/benchmarks/#section=data-r23&test=fortune[TechEmpower Benchmarks - Vert.x Performance]
* link:https://www.postgresql.org/docs/16/textsearch.html[PostgreSQL Full-Text Search]
* link:https://github.com/pgvector/pgvector[pgvector - Vector Similarity Search for PostgreSQL]
* link:https://www.sbert.net/[Sentence-Transformers Documentation]
* link:https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2[all-MiniLM-L6-v2 Model]
* link:https://swagger.io/specification/[OpenAPI Specification]
* link:https://flywaydb.org/documentation/[Flyway Documentation]
